---
title             : "Analyzing the effects of COVID-19 related social media use on well-being"
shorttitle        : "COVID-19 related social media use and well-being"

author: 
  - name          : "Name blinded for review"
    affiliation   : "1"
    corresponding : yes
    address       : ""
    email         : ""

affiliation:
  - id            : "1"
    institution   : ""


abstract          : "In times of crisis such as the Corona pandemic citizens need to stay informed about recent events, political decisions, or mandatory protection measures. To this end, many people use various types of media, and increasingly social media. However, because social media are particularly engaging, some find it hard to disconnect. In this preregistered study, I investigate whether using social media for COVID-19 related reasons affects psychological well-being. To answer this question I analyzed data from the Austrian Corona Panel Project, which consists of 3,018 participants. Well-being was measured at each wave, and communication at five waves. I ran three random effects within between models, controlling for several stable and varying confounders. Results showed that the effects of COVID-19 related social media use on well-being were very small, arguably too small to matter. Fears that social media use during times of crisis critically impairs well-being are likely to be unfounded."
keywords          : "COVID-19, well-being, social media, news use, panel study."

bibliography      : 
  - "bibliography/r-references.bib"
  - "bibliography/references.bib"

floatsintext      : no
endnotes          : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : yes
draft             : no

documentclass     : "apa6"
classoption       : "man"
# output            :
#   papaja::apa6_pdf:
#     latex_engine  : xelatex
output            : papaja::apa6_docx
header-includes:
  - \usepackage{endnotes}
  - \setlength{\parskip}{0em}
  - \raggedbottom
  - \note{\clearpage}
---

```{r analysis-preferences, include=F, cache=F}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed,
                      cache=T, echo=F)
```

```{r setup, include=F, cache=F}

# install necessary packages
# devtools::install_github("https://github.com/tdienlin/td@v.0.0.2.5")
# devtools::install_github("https://github.com/crsh/papaja@devel")

# load packages
packages <- c("devtools", "english", "ggplot2", "gridExtra", "kableExtra", 
              "lavaan", "lme4", "lmerTest",
              "magrittr", "semPlot", "tidyverse")
lapply(c(packages, "papaja", "td"), library, character.only = TRUE)

# load workspace created from analyses.rmd to use results
load("data/workspace_2.RData")
```

During the COVID-19 pandemic, 
numerous events unfolded in quick succession and several open questions emerged.
How dangerous is the virus? 
Is it spreading in my region? 
How is it transmitted, and how can I protect myself?
Because for many it was (and still is) a matter of life or death, people aimed to stay informed regarding the latest developments.
Governments around the world implemented safety measures, such as wearing masks, keeping physical distance, or enforcing lockdowns.
In this extraordinary situation, many people used media excessively to attain information, and especially social media were at an all time high [@statistaAverageDailyTime2021].

Some people actually couldn't stop using social media to learn about COVID-19 related news.
A new phenomenon emerged, termed "doomscrolling":
Users were glued to their screens and found it hard to pursue other relevant activities such as working, taking a break, or looking after their children [@kleinDarklySoothingCompulsion2021].
It was asked whether using social media for COVID-19 related reasons is helpful, or whether it creates an additional burden on mental health [@sandstromDoomscrollingCOVIDNews2021].
These concerns seem justified: 
A study with 6,233 people from Germany conducted during the pandemic found that "[f]requency, duration and diversity of media exposure were positively associated with more symptoms of depression" [@bendauAssociationsCOVID19Related2021, p. 283].

As a result, with this study I want to build on this research and investigate whether or not COVID-19 related social media use affected well-being during the pandemic.
To this end, I analyzed a large-scale panel study from the Austrian Corona Panel Project [@kittelAustrianCoronaPanel2020]. 
The panel consists of 24 waves and has an overall sample size of `r nrow(d_wide) %>% prettyNum(big.mark = ",")` participants.
<!-- At least 1,500 participants took part per wave, and the sample is representative of the Austrian population. -->
The panel study collected a large number of psychological and demographic variables.
<!-- Being able to control for many confounding third variables, both stable and varying, together with the longitudinal design, this creates a unique opportunity  -->
I explicitly aimed to investigate the causal effects of COVID-19 related social media use on well-being.

## Understanding Well-being and Media Use

The underlying theories that guided the selection of variables for my analysis are the two-continua model of mental health [@greenspoonIntegrationSubjectiveWellbeing2001] and the hierarchical taxonomy of computer-mediated communication [@meierComputermediatedCommunicationSocial2020a].
According to the two-continua model, mental health consists of (a) psychopathology and (b) well-being.
<!-- Because the aim of this study is better to understand typical users and everyday contexts, my focus will be on well-being. -->
Well-being can be differentiated into subjective and psychological well-being [@dienerAdvancesOpenQuestions2018].
Whereas subjective well-being emphasizes hedonic aspects such as happiness and joy, psychological well-being addresses eudaimonic aspects such as fulfillment and meaning.
Subjective well-being is primarily about achieving positive affect and avoiding negative affect.
One of the most prominent indicators of well-being is life satisfaction.
In my view, because it represents a general appraisal of one's life, life satisfaction is best thought of as a meta concept that combines psychological and subjective well-being.
Notably, life satisfaction is stable and fluctuates only little, whereas it's the exact opposite for affect [@dienlinImpactDigitalTechnology2020].
<!-- Everyone can feel bad on any given day, but whether or not one feels generally comfortable in one's life rather changes across years. -->
To capture well-being in this study I thus build on life satisfaction, positive affect, and negative affect.
Together, this should provide an encompassing perspective on potential media effects.

The hierarchical taxonomy of computer-mediated communication differentiates six levels of how people engage with digital technology.
First, the device (e.g., smartphone); second, the type of application (e.g., social networking site); third, the branded application (e.g., Twitter); fourth, the feature (e.g., status post); fifth, the interaction (e.g., one-to-many); and sixth, the message (e.g., content) [@meierComputermediatedCommunicationSocial2020a].
Whereas the first four levels focus on the communication _channel_, the last two address the communication _type_.
To measure social media use for the consumption of COVID-19 related news and topics, I here employ both the channel and the type of communication perspective, which together provides a nuanced understanding of communication.

First, I investigate how well-being is affected by different types of communication affect, namely active and passive use.
Defining what constitutes active and what passive use is not always clear, and different understandings are currently discussed [@ellisonWhyWeDon2020, @meierComputermediatedCommunicationSocial2020a].
Reading is generally considered as passive and writing as active, while there are also specific behaviors such as such liking or sharing content that fall somewhere in-between [@meierDoesPassiveSocial2022].
In this study, I hence distinguish (a) _reading_ (passive), (b) _posting_ (active), and (c) _liking and sharing_ COVID-19 related posts (both active and passive).
Second, I analyze how using the most prominent branded applications affects well-being, and whether this effect changes across applications.
Branded apps are separate entities with potentially divergent effects. 
Twitter might have a different effect as compared to WhatsApp because of their respective affordances.
For example, @waterlooNormsOnlineExpressions2018 found that it's more adequate to express negative emotions on WhatsApp than on Twitter or on Instagram. 
The branded applications investigated here are Facebook, Twitter, Instagram, WhatsApp, and YouTube.
Worth noting, this study is not about _general_ social media use during times of COVID, but on social media use _focused_ on COVID-19 related content. 
Examples of such media use include posting thoughts about the pandemic or retweeting COVID-19 related news.

## Theorizing Social Media Effects on Well-Being

<!-- In conclusion, most effects are likely somewhere between trivial and small. -->
<!-- I therefore expect that also in the case of COVID-19 related social media use effects will be trivial to small. -->

From a theoretical perspective, how could we explain whether COVID-19 related social media use might affect well-being?
<!-- In what follows, I outline potential arguments as to why the effect might be positive or negative, direct or indirect, or nonexistent. -->
According to the set-point model of subjective well-being, well-being is surprisingly stable [@lykkenHappinessWhatStudies1999].
Although specific events such as marriage or salary can have significant effects, after some time well-being routinely returns to prior levels, which are mostly determined genetically [@sheldonStabilityHappinessTheories2014].
Only very specific events such as unemployment, disability, or death can cause long-term decreases in well-being [@lucasAdaptationSetpointModel2007].
So although well-being can change this does not happen easily.
<!-- Although the set-point theory has been criticized lately because events such as marriage, unemployment, or death can indeed lead to long-term changes, it is still widely maintained that well-being is very stable and hence hard to be influenced  -->

Can media use be such a negative or positive factor?
In advance, there doesn't seem to be a clear winner, and it's likely that both positive and negative effects cancel each other out.
Empirically, social media use---on average---does not have a strong effect on well-being [@meierComputermediatedCommunicationSocial2020a].
According to the Differential Susceptibility to Media Effects Model [@valkenburgDifferentialSusceptibilityMedia2013], the effects of media use differ across individuals. 
Whereas for some media are beneficial, for others they are harmful.
On average, however, effects are often small or negligible.
Also when focusing on individual users, social media have both positive and negative effects on well-being [@buchiDigitalWellbeingTheory2021].
They can impair well-being when causing embarrassment, stress, or disinformation, and they can improve well-being when providing connectedness, information, or entertainment [@buchiDigitalWellbeingTheory2021].

Two of the most prominent media effect theories argue against strong negative impacts.
First, uses and gratifications theory states that people explicitly and rationally chose specific media because of their respective benefits. 
If those benefits don't exist, they invest their time elsewhere.
And social media offer ample benefits. 
Most prominently, they help find relevant information, maintain and foster relationships, express one's personality, and entertain oneself [@pelletierOneSizeDoesn2020].
The second major theory is mood management theory [@zillmannMoodManagementCommunication1988].
Users implicitly learn what media help them balance their mood and affect.
For example, when bored people use social media to entertain themselves.
Using experience sampling of well-being and logs of social media use, a study with 82 participants from Italy found that after episodes of social media use, levels of positive affect increased for a short time [@marcianoDynamicsAdolescentsSmartphone2022].

But people also misjudge media affects, often being overly optimistic [@metzgerComparativeOptimismPrivacy2017].
And precisely because social media have so many positive consequences, one can ask if this where the actual problem lies.
In other words, social media aren't problematic because they're inherently bad, but rather because they're too good.
And as with many other things, there can be too much of a good thing.
It is therefore often asked whether social media are addictive, and users sometimes express this fear themselves [@yangCanWatchingOnline2021]. 
However, a recently published meta-analysis found that the two most prominent measures of addiction, the Bergen Facebook Addiction Scale and the Bergen Social Media Addiction Scale, have only small relations to well-being [@duradoniWellbeingSocialMedia2020]. 
In addition, the general idea of labeling excessive social and new media use as addiction was criticized, arguing that social and new media represent new regular behaviors that should not be pathologized [@galerHowMuchToo2018; @vanrooijWeakScientificBasis2018].

Because effects can differ across situations, I now briefly focus on the effects of COVID-19 related social media use specifically.
First, one could assume a _direct_ negative effect on well-being, and especially on positive or negative affect, which are more volatile and fluctuating.
Dangers, inequalities, corruption---these were the headlines during the pandemic across many countries worldwide.
If one learns about such events, the initial reaction might be shock, fear, or dismay.
Consuming such news can be depressing [@dornemannHowGoodBad2021], perhaps even changing some general perspectives on life.
<!-- So, just like being hit by a hammer hurts and we don't need any "mediating mechanism", this could be the case here as well. -->
That said, because not all news was negative, and because many people showed solidarity and compassion, there was also positive and uplifting content, potentially compensating for the negative effects [@dornemannHowGoodBad2021].
A study with 2.057 respondents from Italy reported that during the pandemic virtual community and social connectedness even increased during the pandemic [@guazziniSecondWaveAnalysis2022].
<!-- However, in light of a worldwide pandemic with millions of deaths, the negative direct effect seems more plausible. -->

There could also be _indirect_ effects.
When browsing social media for Covid-19 related news, many users reported being captivated to such an extent that they could not stop using social media [@kleinDarklySoothingCompulsion2021].
During the pandemic social media use was at an all-time high in the US [@statistaAverageDailyTime2021].
It is most likely that moderate social media use is not detrimental [@orbenTeenagersScreensSocial2020].
Overuse, however, might be more critical, and several studies have shown more pronounced negative effects for extreme users [@przybylskiLargescaleTestGoldilocks2017].
To explain, overuse could impair well-being if it replaces meaningful or functional activities such as meeting others, working, actively relaxing, or exercising.
So if a society collectively overuses social media during a pandemic, there might be potential for negative effects.
<!-- If overuse replaces such activities it's reasonable to assume that it's also detrimental. -->
On the other hand, one can make the case that overuse might also be beneficial, especially in times of a pandemic---even if the use is mainly COVID-19 related.
Exchanging COVID-19 related messages with friends via WhatsApp might replace the in-person contact one would have otherwise, but which is literally impossible at the time.
In situations where meaningful and functional activities are prohibited, using social media to exchange about COVID-19 related topics might not be the worst idea.
Besides, given that nowadays a large number of experts, scientists, and politicians converse directly on social media, one can get first-hand high quality information on current developments.
<!-- On the other hand, there is of course also much disinformation, and "bingeing" on COVID-19 fake news might also pose risks for impaired well-being. -->

To summarize, from a theoretical perspective it is most likely that the average effects of social media use on well-being are negligible. 
Building on established theories from Communication, it is not particularly likely that effects are either profoundly negative or strongly positive.

## Empirical Studies on Social Media Effects

So far, there is only little empirical research on how well-being is affected by COVID-19 related social media.
In their study on the relations between media use and mental health during the pandemic, @bendauAssociationsCOVID19Related2021 found that people who used social media as a primary source of information reported on average "significantly more unspecific anxiety and depression [] and significantly more specific COVID-19 related anxiety symptoms" (p. 288).
@edenMediaCopingCOVID192020 analyzed the media use of 425 US college students during the first wave of the pandemic, finding both positive and negative relations with well-being.
In a sample of 312 respondents collected via Amazon Mechanical Turk, @choiMediatedCommunicationMatters2021 reported that people who used media to attain information were more lonely and less satisfied with their lives.
@stainbackCOVID1924News2020 analyzed a large-scale study with 11,537 respondents from the US and found that increased COVID-19 media consumption was related to more psychological distress.
A four-wave panel study with 384 young adults from the U.S. analyzed the effects of general digital technology use---objectively measured via screenshots of screen-time applications---on mental health, separating within- and between-person relations [@sewallObjectivelyMeasuredDigital2021].
The results showed that digital technology did not have any significant effects on mental health [for a similar study with comparable results, see @bradleyStressMoodSmartphone2021].
Together, the literature is mixed, with a slight focus on the negative effects of social media as news use [see also @dornemannHowGoodBad2021; @liuRelationOfficialWhatsAppdistributed2020; @riehmAssociationsMediaExposure2020].
However, note that all of these findings represent between-person relations stemming from cross-sectional data (see below).
We therefore don't know whether the differences in mental health and well-being are due to social media use or due to other third variables, such as age, health, employment, or education.

The question of whether and how social media use affects well-being _in general_, on the other hand, is well-researched.
This also holds true for the different types of communication such as active or passive use.
A meta review (i.e., an analysis of meta-analyses) found that the relation between social media use and well-being is likely in the negative spectrum but very small [@meierComputermediatedCommunicationSocial2020a]---potentially too small to matter.
What determines whether or not an effect is considered small or trivial?
As a starting point, we could refer to standardized effect sizes.
According to @cohenPowerPrimer1992, small effect sizes start at _r_ = .10.
And indeed, several if not most of the current meta-analyses find effect sizes below that threshold [@huangTimeSpentSocial2017; @meierComputermediatedCommunicationSocial2020a; @fergusonThisMetaanalysisScreen2021].

Several individual studies employing advanced methods found smalls relations between social media use and well-being [@orbenSocialMediaEnduring2019; @przybylskiDoesTakingShort2021a; @schemerImpactInternetSocial2021; @kerestesAdolescentsOnlineSocial2020].
For example, @beyensSocialMediaUse2021 reported that although for some users (roughly one quarter) the effects of social media use on well-being were negative, for almost the same number of users they were positive, while for the rest the effects were neutral.
This finding is aligned the Differential Susceptibility to Media Effects Model.
Although there is substantial variation of media effects for individual users, the average effects reported in the literature are often small [@valkenburgDifferentialSusceptibilityMedia2013]. 

<!-- Together, the strongest argument to me is that _in general_ the effects of social media on well-being are, on average, small at best.  -->
<!-- Because this study only looks at _one part_ of social media use---namely, COVID-19 related interactions---it is very focused, diminishing the overall potential of the effects even further. -->
<!-- Whether or not using social media for COVID-19 related aspects is detrimental during a pandemic is also not entirely clear. -->
<!-- At least, there does not seem to be a case where we should expect a clear deviation to the negative, despite anecdotes of doomscrolling. -->

In conclusion, in light of the theoretical considerations and the empirical studies presented above, I expect that COVID-19 related communication on social media doesn't affect well-being in a meaningful or relevant way.

> Hypothesis: The within-person effects of all types of COVID-19 related social media use on all types of well-being indicators---while controlling for several stable and varying covariates such as sociodemographic variables and psychological dispositions---will be trivial.

# Current Study
## Smallest Effect Size of Interest

Testing this hypothesis, however, is not trivial.
First, in contrast to most hypotheses typically posited in the social sciences it implicitly contains an effect size, a so-called smallest effect size of interest (SESOI).
Effectively testing this hypothesis necessitates defining what's considered a "trivial effect size" and what's not.
Above I already referred to standardized effect sizes.
However, standardized effect sizes should only be a first step toward evaluating an effect's relevance [@baguleyStandardizedSimpleEffect2009].
Standardized effect sizes are determined by a sample's variance,[^cohensd] which is problematic: 
The question of whether or not social media use affects a particular person in a relevant way should not depend on the variance in the sample in which that person's data were collected.
Instead, it should depend on absolute criteria.

What could be a minimally interesting, nontrivial effect?
Because this is a normative and ultimately philosophical question, there can never be a clear, single, or unanimous answer. 
<!-- In the end, it is a personal question. -->
However, it is still necessary and helpful to try provide such a plausible benchmark. 
I therefore suggest the following SESOI for this research question:

[^cohensd]: Consider the effect size Cohen's _d_: The mean's of the two groups that are to be compared are subtracted from one another and then divided by the sample's standard deviation [@cohenPowerPrimer1992]. Hence, if there is more deviation/variance in a sample, the effect size decreases, even if the difference of the group's means stays the same.

> SESOI: If a heavy user of COVID-19 related social media news suddenly _stops_ using social media altogether, this should have a _noticeable_ impact on their overall well-being.

What does this mean practically and how can it be operationalized?
In this study, COVID-19 related social media use was measured on a 5-point scale, ranging from 1 = _never_ to 5 = _several times a day_. 
Thus, a change of four units in social media use (e.g., a complete stop) should correspond to a noticeable change in well-being.
But what's a noticeable change in well-being?
According to @normanInterpretationChangesHealthrelated2003, people can reliably distinguish _seven_ levels of satisfaction with health.
So if satisfaction is measured on a 7-point scale, we would state that a four unit change in social media use should result in a one unit change in life satisfaction. 
(For more information, see Methods section "Inference Criteria.")

## Causality

The hypothesis explicitly states a causal effect.
In non-experimental studies, longitudinal designs can help investigate causality.
Using longitudinal designs alone, however, is not sufficient for establishing correct causal statements [@rohrerTheseAreNot2021].
In addition, we for example also need to control for confounding third variables, and importantly also for _varying_ third variables.

To illustrate, consider the following example.
Imagine that a person suddenly starts using social media much more than usual, and then after some time  becomes less satisfied with their life.
Eventually, use and life satisfaction return to prior levels.
If this happens to several people at the same time, in a longitudinal study we could then observe a significant effect of social media use on life satisfaction.
However, it could also be the case that during the study there was a major exogenous event (say, a pandemic), which caused large parts of the working population to loose their jobs.
Hence, the causal effect reported above was confounded, because in reality it was the pandemic that caused both social media use to rise and life satisfaction to go down.

Thus, only when controlling for _all_ relevant confounders, we can correctly estimate causality without bias [@rohrerThinkingClearlyCorrelations2018].
Obviously, we can never be entirely sure to have included all confounders, which makes absolute statements regarding causality virtually impossible.
In addition, when determining the overall causal effect, we need to make sure _not_ to control for mediating variables [@rohrerThinkingClearlyCorrelations2018], for doing so would bias our assessment of the causal effect.
Complicating matters further, it is often unclear if a variable is a mediator or a confounder.[^collider]
However, despite all these caveats, when controlling for relevant variables (that aren't mediators), we can be much more certain that we measured causality correctly.
The aim should therefore be to collect as many varying and nonvarying confounders as possible (which I believe is seldom done in our field), while knowing that absolute certainty regarding causality cannot be reached.

[^collider]: In addition, there also exist colliders, which I don't discuss here and which complicate the issue even further [@rohrerThinkingClearlyCorrelations2018].

When searching for suitable candidates for confounders, we should look for variables that affect both media use and well-being. 
Controlling for these factors isolates the actual effect of social media use on well-being.
We can also control for variables that affect only social media use or well-being. 
However, in doing so not much is gained or lost, because the effects of social media use would remain virtually the same [@klinePrinciplesPracticeStructural2016; but see @mcelreathYesterdayClass2021].

In this study, I hence plan to control for the following variables, which either have already been shown to affect both social media use and well-being or which are likely to do so, and which also aren't mediators:
<!-- (I'll additionally include variables that likely affect only well-being, also to obtain a comparison benchmark for social media effects): -->
gender, age, education, Austria country of birth, Austria country of birth of parents, text-based news consumption, video-based news consumption, residency Vienna, household size, health, living space, access to garden, access to balcony, employment, work hours per week, being in home-office, household income, outdoor activities, satisfaction with democracy, disposition to take risks, and locus of control.
<!-- I will not control for variables such as trust in institutions or trust in media, because these variables might be influenced by social media use to a meaningful extent. -->
The dataset includes many other variables that one could also potentially control for, and I invite interested readers to download the and explore potential interesting relationships.

Next to including covariates, it's now increasingly understood that causal effects should be analyzed from an internal, within-person perspective [@hamakerWhyResearchersShould2014].
If a specific person changes their media diet, we need to measure how this behavior affects _their own_ well-being.
Between-person comparisons from cross-sectional data, where participants are interviewed only once, cannot provide such insights.
In this study, I hence differentiate between-person relations from within-person effects. 
And as explicated above, to test the hypothesis I thus consider only the within-person effects.

Finally, one precondition of causality is temporal order. 
The cause needs to precede the effect.
Finding the right interval between cause and effect is crucial.
For example, if we want to understand the effect of alcohol consumption on driving performance, it makes a big difference if driving performance is measured one minute, one hour, one day, or one week after consumption.
<!-- Finding the right interval is difficult. -->
If variables are stable, longer intervals are needed; if they fluctuate, shorter intervals.
In the case of well-being, we need shorter intervals for affect and longer ones for life satisfaction.
Still, choosing the right interval is challenging, because especially short intervals are hard to implement in practice and often require advanced methods such as experience sampling (also known as in situ measurement or ambulant assessment) [@schnauber-stockmannMobileDevicesTools2020].

In this study, I analyze how using social media during the last week affected their positive and negative affect during the last week.
More precisely, if people during the last week used COVID-19 related social media more than the usually do, did they feel better or worse during that week than they usually do?
Regarding life satisfaction, I implemented a longer interval.
Namely, if people during the last week used COVID-19 related social media more than the usually do, did this affect if they are now more or less satisfied with their lives than they usually are?
I hence analyze if when a person changes their social media diet, are there (a) _simultaneous_ changes in their affect and (b) _subsequent_ changes in their life satisfaction?
When additionally controlling for both stable and varying confounders, we can then be more sure that the effect is indeed causal.
Similar approaches were implemented by other studies [@johannesNoEffectDifferent2022; @scharkowHowSocialNetwork2020], and they are considered a best practice to analyze causality [@bellFixedRandomEffects2019].

# Method

In this section I describe the preregistration and how I determined the sample size, data exclusions, the analyses, and all measures in the study.

## Preregistration

The hypotheses, the sample, the measures, the analyses, and the inference criteria (SESOI, p-value) were preregistered on the Open Science Framework. 
The (anonymous) preregistration can be accessed here: https://osf.io/87b24/?view_only=b2289b6fec214fa88ee75a18d45c18f3.
Because in this study I analyzed data from an already existing large-scale data set, all of these steps were done prior to accessing the data.
The preregistration was designed on the basis of the panel documentation online [@kittelAustrianCoronaPanel2020].
In some cases I couldn't execute the analyses as I had originally planned, for example because some properties of the variables only became apparent when inspecting the actual data.
The most relevant deviations are reported below, and a complete list of all changes can be found in the online [companion website](https://XMtRA.github.io/Austrian_Corona_Panel_Project) (https://XMtRA.github.io/Austrian_Corona_Panel_Project).

## Sample

The data come from the Austrian Corona Panel Project [@kittelAustrianCoronaPanel2021].
The study was conducted between March 2020 and October 2021.
It contains 26 waves, and at the time of writing the first 24 waves were available for download. 
Each wave consists of at least 1,500 respondents.
The overall sample size was _N_ = `r d_raw %>% nrow() %>% prettyNum(big.mark = ",")`, and `r d_long %>% nrow() %>% prettyNum(big.mark = ",")` observations were collected.
Panel mortality was compensated through a continuous acquisition of new participants. 
All respondents needed to have access to the internet (via computer or mobile devices such as smartphones or tablets).
They were sampled from a pre-existing online access panel provided by the company Marketagent, Austria.
Respondents were asked and incentivized with 180 credit points to participate in each wave of the panel.

Achieved via quota sampling, the sample matched the Austrian population in terms of age, gender, region/state, municipality size, and educational level.
In order to participate in the study, the respondents needed to be Austrian residents and had to be at least 14 years of age. 
Ethical review and approval was not required for the study in accordance with the local legislation and institutional requirements. 
The participants provided their written informed consent to participate in this study.
The average age was `r mean(2021 - d_wide$year_birth, na.rm = T) %>% round(0)` years, `r mean(d_wide$male, na.rm = T) %>% round(., 2) * 100` percent were male, `r (d_wide %>% filter(.$edu_fac %in% c("State college", "Bachelor", "Master", "PhD"))) %>% nrow() %>% divide_by(sum(table(d_wide$edu_fac))) %>% multiply_by(100) %>% round(0)` percent had a University degree, and `r (table(d_wide$employment_fac)["Unemployed"] / sum(table(d_wide$employment_fac))) %>% unname() %>% multiply_by(100) %>% round(., digits = 0)` percent were currently unemployed.

## Inference Criteria

Because the data were analyzed post-hoc, no a-priori sample size planning on the basis of power analyses was conducted.
The sample is large, and it is hence well-equipped reliably to detect also small effects.
<!-- , which is why no exact post hoc power analysis were conducted. -->
In addition, because such large samples easily generate significant _p_-values even for very small effects, it helps that the hypotheses were tested with a smallest effect size of interest-approach.
To this end, I adopted the interval testing approach as proposed by @dienesUsingBayesGet2014.
On the basis of the SESOI, I then defined a null region.
In what follows, I explain how I determined the SESOI and the null region.

In this study, life satisfaction was measured on an 11-point scale.
If people can reliably differentiate 7 levels as mentioned above, this corresponds to 11 / 7 = `r round(11/7, 2)` unit change on an 11-point scale.
Hence, a four-point change in media use (e.g., a complete stop) should result in a `r round(11/7, 2)`-point change in life satisfaction.
In a statistical regression analysis, _b_ estimates the change in the dependent variable if the independent variable increases by one point.
We would therefore expect a SESOI of _b_ = `r round(11/7, 2)` / 4 = `r round(11/7*.25, 2)`.
For affect, which was measured on a 5-point scale, our SESOI would be _b_ = `r round(5 / 7, 2)` / 4 = `r round(5 / 7 * .25, 2)`.
Because we're agnostic as to whether the effects are positive or negative, the null region includes negative and positive effects.
Finally, in order not to exaggerate precision and to be less conservative, these numbers are reduced to nearby thresholds.[^rounding] 
Together, this leads to a null region ranging from _b_ = -.30 to _b_ = .30 for life satisfaction, and _b_ = -.15 to _b_ = .15 for positive and negative affect.

[^rounding]: Note that other researchers also decreased or recommended decreasing thresholds for effect sizes when analyzing within-person or cumulative effects [@beyensSocialMediaUse2021; @funderEvaluatingEffectSize2019].

<!-- As explained above, for well-being the null region was between _b_ = -.30 and _b_ = .30 (i.e., _b_ = |.30|). -->
Let's briefly illustrate what this means in practice.
If the 95% confidence interval falls completely within the null-region (e.g., _b_ = .20, [95% CI: .15, .25]), the hypothesis that the effect is trivial is supported.
If the confidence interval and the null region overlap (e.g., _b_ = .30, [95% CI: .25, .35]), the hypothesis is not supported and the results are considered inconclusive, while a meaningful negative effect is rejected.
If the confidence interval falls completely outside of the null-region (e.g., _b_ = .40, [95% CI: .35, .45]), the hypothesis is rejected and the existence of a meaningful positive effect is supported.
For an illustration, see Figure \@ref(fig:sesoi)).

<!-- Responses were individually checked for patterns such as straight-lining or missing of inverted items. -->
<!-- X clear cases were removed. -->

## Data Analysis

The hypothesis was analyzed using mixed effects models, namely random effect within-between models (REWB)[@bellFixedRandomEffects2019]. 
Three models were run, one for each dependent variable.
The data were hierarchical, and responses were separately nested in participants and waves (i.e., participants and waves were implemented as random effects).
Nesting in participants allowed to separate between-person relations from within-person effects.
Nesting in waves allowed to control for general exogenous developments, such as general decreases in well-being in the population, for example due to lockdown measures.
Thus, there was no need additionally to control for specific phases or measures of the lockdown.
Predictors were modeled as fixed effects.
They included social media communication types and channels, separated into within and between-person factors, as well as stable and varying covariates.
All predictors were included simultaneously and in each of the three models. 

The factorial validity of the scales were tested with confirmatory factor analyses (CFA).
Because Mardia’s test showed that the assumption of multivariate normality was violated, I used the more robust Satorra-Bentler scaled and mean-adjusted test statistic (MLM) as estimator.
To avoid overfitting, I tested the scales on more liberal fit criteria (CFI > .90, TLI > .90, RMSEA <. .10, SRMR < .10) [@klinePrinciplesPracticeStructural2016].
Finally, REWB-models cannot model latent variables.
To increase precision, I therefore exported factor scores from the CFAs for positive and negative affect.
Respondents who answered less than 50% of all questions were removed.
The remaining missing responses were imputed using predictive mean matching.

For more information on the analyses, a complete documentation of the models and results, additional analyses (for example using multiple imputation or no imputation), see [companion website](https://XMtRA.github.io/Austrian_Corona_Panel_Project).

## Measures

In what follows, I list all the variables that I analyzed.
For the variables' means, range, and variance, see Table \@ref(tab:tab-descriptives).
For a complete list of all items and item characteristics, see [companion website](https://XMtRA.github.io/Austrian_Corona_Panel_Project).

### Well-being

Life satisfaction was measured with the item "All things considered, how satisfied are you with your life as a whole nowadays?" from the European Social Survey [@europeansocialsurveyESS9Edition20182021].
The response options ranged from 0 (_extremely dissatisfied_) to 10 (_extremely satisfied_).

To capture positive affect, respondents were asked how often in the last week they felt (a) calm and relaxed, (b) happy, and (c) full of energy [@worldhealthorganizationWellbeingMeasuresPrimary1998].
The response options were 1 (_never_), 2 (_on some days_), 3 (_several times per week_), 4 (_almost every day_), and 5 (_daily_).
The scale showed good factorial fit, `r fit_txt(cfa_aff_pos)`.
Reliability was high, $\omega$ = `r rel_aff_pos %>% my_round("std")`.

For negative affect, respondents were asked how often in the last week they felt (a) lonely, (b) aggravated, (c) so depressed, that nothing could lift you up, (d) very nervous, (e) anxious, and (h) glum and sad [@worldhealthorganizationWellbeingMeasuresPrimary1998].
The response options were 1 (_never_), 2 (_on some days_), 3 (_several times per week_), 4 (_almost every day_), and 5 (_daily_).
The scale showed good factorial fit, `r fit_txt(cfa_aff_neg)`.
Reliability was high, $\omega$ = `r rel_aff_neg %>% my_round("std")`.

All three variables were measured on each wave.

### COVID-19 related social media use

COVID-19 related social media use focused on communication types was measured with the three dimensions of (a) reading, (b) liking and sharing, and (c) posting.
The items come from @wagnerAUTNESOnlinePanel2018 and were adapted for the context of this study.
The general introductory question was "How often during the last week have you engaged in the following activities on social media?"
The three items were "Reading the posts of others with content on the Coronavirus", "When seeing posts on the Coronavirus, I clicked 'like', 'share' or 'retweet'", "I myself wrote posts on the Coronavirus on social media."
Answer options were 1 (_several times per day_), 2 (_daily_), 3 (_several times per week_), 4 (_weekly_), 5 (_never_).
The items were inverted for the analyses.

COVID-19 related social media use focused on channels was measured with five variables from @wagnerAUTNESOnlinePanel2018, adapted for this study. 
The general introductory question was "How often in the last week have you followed information related to the Corona-crisis on the following social media?"
The five items were (a) Facebook, (b) Twitter, (c) Instagram, (d) Youtube, and (e) WhatsApp.
Again, the answer options were 1 (_several times per day_), 2 (_daily_), 3 (_several times per week_), 4 (_weekly_), 5 (_never_).
Again, the items were inverted for the analyses.

Social media use was measured for all participants on waves 1, 2, 8, 17, and 23. 
Freshly recruited respondents always answered all questions on social media use.

### Control variables

The effects of COVID-19 related social media use were controlled for the following stable variables: 
(a) gender (female, male, diverse), (b) age, (c) education (ten options), (d) Austria country of birth (yes/no), (e) Austria parents' country of birth (no parent, one parent, both parents).
I originally planned to implement additional variables as varying covariates.
However, because they were not measured often enough or not at the time when social media use was measured, I implemented them as stable variables using their average values across all waves.
This includes (a) text-based media news consumption (five degrees), (b) video-based media news consumption (five degrees), (c) residency is Vienna (yes/no), (d) self-reported physical health (five degrees), (e) living space (eleven options), (f) access to balcony (yes/no), (g) access to garden (yes/no), (h) employment (nine options), (i) disposition to take risks (eleven degrees), and (j) locus of control (five degrees).
I also controlled for the following varying covariates: (a) five items measuring outdoor activities such as sport or meeting friends (five degrees), and (b) satisfaction with democracy (five degrees).
Because it lead to too much attrition in the sample, I did not control for (a) household size, (b) work hours per week, (c) home office, (d) household income.

# Results

First, when looking at the variables from a descriptive perspective (Figure \@ref(fig:descriptives))), we see that all well-being measures did not change substantially across the different waves of data collection.
COVID-19 related media use, however, decreased slightly at the beginning of the study and remained stable after approximately six waves.
The initial decrease might be explained by the fact that the collection of data began at the end of March 2020, hence approximately three months after the pandemic began.
It could be that after an initial uptick, COVID-19 related social media use was already declining at the time, returning to more normal levels.

## Preregistered Analyses

The study's main hypothesis was that the effects of social media use on well-being would be trivial.
Regarding the effects of different communication _types_---that is, reading vs. sharing vs. posting---all within-person effects fell completely within the a-priori defined null region (see Figure \@ref(fig:res-activity)).
For example, respondents who used social media more frequently than usual to read about COVID-19 related topics did not show a simultaneous change in life satisfaction (_b_ = `r dat_fig_results_activity %>% filter(dv == "Life satisfaction" & iv == "Reading" & type == "within" & Analysis == "1. regular") %>% select(estimate) %>% round(2)` [95% CI `r dat_fig_results_activity %>% filter(dv == "Life satisfaction" & iv == "Reading" & type == "within" & Analysis == "1. regular") %>% select(conf.low) %>% round(2)`, `r dat_fig_results_activity %>% filter(dv == "Life satisfaction" & iv == "Reading" & type == "within" & Analysis == "1. regular") %>% select(conf.high) %>% round(2)`]).
All confidence intervals included zero; hence, all effects were also statistically non-significant.
As a result, the hypothesis was supported for all COVID-19 related types of social media communication.

Regarding between-person relations, about which no hypotheses were formulated, only three effects did not include zero.
Respondents who across all waves used social media more frequently than others to read about COVID-19 related posts reported slightly lower levels of positive affect than others (_b_ `r dat_fig_results_activity %>% filter(dv == "Positive affect" & iv == "Reading" & type == "between" & Analysis == "1. regular") %>% select(estimate) %>% my_round("b_txt")` [95% CI `r dat_fig_results_activity %>% filter(dv == "Positive affect" & iv == "Reading" & type == "between" & Analysis == "1. regular") %>% select(conf.high) %>% my_round("b")`, `r dat_fig_results_activity %>% filter(dv == "Positive affect" & iv == "Reading" & type == "between" & Analysis == "1. regular") %>% select(conf.low) %>% my_round("b")`]).
Respondents who across all waves used social media more frequently than others to write COVID-19 related posts reported higher levels of negative affect than others (_b_ `r dat_fig_results_activity %>% filter(dv == "Negative affect" & iv == "Posting" & type == "between" & Analysis == "1. regular") %>% select(estimate) %>% my_round("b_txt")` [95% CI `r dat_fig_results_activity %>% filter(dv == "Negative affect" & iv == "Posting" & type == "between" & Analysis == "1. regular") %>% select(conf.high) %>% my_round("b")`, `r dat_fig_results_activity %>% filter(dv == "Negative affect" & iv == "Posting" & type == "between" & Analysis == "1. regular") %>% select(conf.low) %>% my_round("b")`]).
Interestingly, respondents who across all waves used social media more frequently than others to write COVID-19 related posts also reported slightly higher levels of positive affect than others (_b_ `r dat_fig_results_activity %>% filter(dv == "Positive affect" & iv == "Posting" & type == "between" & Analysis == "1. regular") %>% select(estimate) %>% my_round("b_txt")` [95% CI `r dat_fig_results_activity %>% filter(dv == "Positive affect" & iv == "Posting" & type == "between" & Analysis == "1. regular") %>% select(conf.high) %>% my_round("b")`, `r dat_fig_results_activity %>% filter(dv == "Positive affect" & iv == "Posting" & type == "between" & Analysis == "1. regular") %>% select(conf.low) %>% my_round("b")`]).
However, note that the effect were still completely inside of the null region, hence not large enough to be considered practically relevant.

Note that when comparing the results with and without control variables, the results differed.
For example, on the between-person level, one effect stopped being significant if controlled for additional variables.
Actively posting on social media was significantly (though not meaningfully) related to decreased life satisfaction.
However, when controlling for potential confounders, the effect became virtually zero (see Figure \@ref(fig:res-channels)).

Regarding the COVID-19 related use of social media _channels_, the results were comparable (see Figure \@ref(fig:res-channels)).
Changes in the frequency of using different social media channels to attain information regarding COVID-19 were unrelated to meaningful changes in well-being.
For example, respondents who used Facebook more frequently than usual to learn about COVID-19 did not show a simultaneous change in well-being (_b_ = `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Facebook" & type == "within" & Analysis == "1. regular") %>% select(estimate) %>% round(2)` [95% CI `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Facebook" & type == "within" & Analysis == "1. regular") %>% select(conf.low) %>% round(2)`, `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Facebook" & type == "within" & Analysis == "1. regular") %>% select(conf.high) %>% round(2)`]).
Only two effects differed substantially from zero.
Respondents who used Instagram more frequently than usual to attain COVID-19 related news reported slightly _higher_ levels of life satisfaction than usual (_b_ = `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Instagram" & type == "within" & Analysis == "1. regular") %>% select(estimate) %>% my_round("b")` [95% CI `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Instagram" & type == "within" & Analysis == "1. regular") %>% select(conf.low) %>% my_round("b")`, `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Instagram" & type == "within" & Analysis == "1. regular") %>% select(conf.high) %>% my_round("b")`]).
Respondents who used Twitter more frequently than usual to attain COVID-19 related news reported slightly _lower_ levels of life satisfaction than usual (_b_ = `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Twitter" & type == "within" & Analysis == "1. regular") %>% select(estimate) %>% round(2)` [95% CI `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Twitter" & type == "within" & Analysis == "1. regular") %>% select(conf.low) %>% round(2)`, `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "Twitter" & type == "within" & Analysis == "1. regular") %>% select(conf.high) %>% my_round("b")`]).
However, both effects were still completely inside of the null region, hence not large enough to be considered meaningful.
In sum, the hypothesis was supported also for the COVID-19 related use of important social media channels.

In terms of between-person relations---which, again, weren't included in the hypotheses---no relations crossed the null region or fell outside of it.
Only one relation did not include zero, was hence statistically significant. 
Respondents who across all waves used YouTube more frequently than others for COVID-19 related reasons reported marginally _higher_ levels of life satisfaction (_b_ = `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "YouTube" & type == "between" & Analysis == "1. regular") %>% select(estimate) %>% round(2)` [95% CI `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "YouTube" & type == "between" & Analysis == "1. regular") %>% select(conf.low) %>% my_round("b_txt")`, `r dat_fig_results_channels %>% filter(dv == "Life satisfaction" & iv == "YouTube" & type == "between" & Analysis == "1. regular") %>% select(conf.high) %>% my_round("b")`]).
However, please note that this effect again was not large enough to be considered practically relevant.

Again, note that when comparing the results with and without control variables, the results differed.
Especially on the between-person level, altogether five effects stopped being significant if they were controlled for additional variables.
For example, using Instagram was significantly (though not meaningfully) related to increased life satisfaction.
However, when controlling for additional covariates, the effect became virtually zero (see Figure \@ref(fig:res-channels)).

## Exploratory Analyses

In what follows, I briefly report some exploratory analyses that weren't preregistered.
First, to contextualize the results reported above and to see if the results included any meaningful effects at all, I also looked at the effect sizes of selected (cherry-picked) covariates.
Because each variable had different response options, we would actually need to define a SESOI for each variable, which for reasons of scope I cannot implement here. 
Therefore, I report the results of the standardized scales,
which allows for a better comparison across the differently scaled variables.
For what it's worth, as a rough estimate for the SESOI we can build on the typical convention that small effects start at _r_ = |.10|.
The results showed that several effects fell outside of the SESOI, were hence considered meaningful.
This includes for example internal locus of control, health, satisfaction with democracy, or exercising.
For an overview, see Figure \@ref(fig:res-control).

To find out whether my inferences were robust across legitimate (though arguably inferior) alternative analyses, I reran the analyses also using standardized estimates, mean scores instead of factor scores, and with a data set where missing data were not imputed.
The results were virtually the same.
For example, all standardized COVID-19 related types of social media use or channels were not significantly larger than a SESOI of $\beta$ = |.10|.
The additional analyses are reported in the [companion website](https://XMtRA.github.io/Austrian_Corona_Panel_Project/analyses_additional.html).

# Discussion

In this study I analyzed the effects of COVID-19 related social media use on well-being.
The data come from a panel study with 24 waves and are largely representative of the Austrian population.
In a random effects model I separated between person relations from within-person effects and controlled for a large number of both stable and varying covariates, thereby aiming to assess causality.
The results showed that within-person effects were trivial.
People who used social media more than usual to learn about COVID-19 didn't show meaningful changes in their well-being.

The results imply that COVID-19 related social media use doesn't seem to be particularly relevant for well-being.
Other factors among the third variables that were measured revealed larger effects or relations, suggesting that well-being is determined by alternative aspects such as health, satisfaction with democracy, locus of control, or exercising.
According to this study, popular fears that "doomscrolling" or overusing social media during times of crises don't seem to be justified.

On the one hand, the results are not aligned with several recent studies analyzing similar or closely related research questions.
This includes a study by @bendauAssociationsCOVID19Related2021, which showed negative relations between social media and well-being [but see @bradleyStressMoodSmartphone2021; or @sewallObjectivelyMeasuredDigital2021].
However, note that @bendauAssociationsCOVID19Related2021 analyzed cross-sectional data on a between-person level while not controlling for third variables, which is not optimal for investigating causal effects.
On the other hand, the results are well-aligned with recent studies and meta-analyses analyzing the effects of social media use from a more general perspective or from a somewhat different angle. 
These studies have found that the effects of various types of social media use on several well-being indicators are small at best, often too small to matter [@meierComputermediatedCommunicationSocial2020a; @orbenTeenagersScreensSocial2020; @fergusonThisMetaanalysisScreen2021], which echoes the results obtained here.

If anything, two preliminary and subtle trends can be observed.
First, in terms of media channels, using Twitter more than usual was related to slightly decreased levels of life satisfaction.
Twitter is considered to have more negative affordances and tonality as compared to other networks such as Instagram [@waterlooNormsOnlineExpressions2018], which might help explain the results.
Instagram, on the other hand, was related to slightly increased levels of life satisfaction.
To speculate, the often-criticized positivity bias on Instagram might have been somewhat beneficial in times of the pandemic.
The critique that the positivity bias necessarily leads to envy and negative feelings is unrealistic and myopic, because positive content can also inspire and motivate users [@meierInstagramInspirationHow2020].
Second, of all the three COVID-19 related social media activities, people who read about the pandemic more than others showed slightly decreased levels of positive affect, and people who actively posted about the pandemic more than others showed slightly increased levels of negative affect.
On the other hand, however, people who posted more about COVID-19 also showed slightly higher levels of positive affects, so taken together the results are ambivalent.
But future research might elaborate on these specific relations to probe their stability and relevance.

<!-- Finally, another interesting observation is that life satisfaction was remarkably stable. -->
<!-- Hence, even in times of a pandemic, it seems that such broad assessment of life vary only mildly. -->
<!-- This supports the hypothesis that life satisfaction seems to be determined largely by stable factors such as one's genes [@brownEasyHappinessPie2019]. -->

## Limitations

The current study analyzed whether changes in media use were related to changes in well-being, while controlling for several potential confounders. 
Together, this allows for an improved perspective on assessing causality.
That said, causality necessitates temporal order, and the cause needs to precede the effect.
Regarding media use, such effects often happen immediately or shortly after use, necessitating intervals in the hours, minutes, or even seconds.
In many cases only experience sampling studies asking users in the very moment can produce such knowledge.
However, even then we don't know for certain if we actually measured the right interval.
Effects depend on the intensity of use or the length of the interval, and to borrow the words from @rohrerTheseAreNot2021, there is no such thing as "the" effect of social media use on well-being.
Hence, to document how effects unfold, future research needs to employ different study designs probing different time lags.
In addition, more thought needs to be invested in what relevant stable and varying factors we should include as control variables, and I hope this study provides a first step into this direction.

Although I had already reduced the predefined SESOIs to be less conservative, they were potentially still too large.
Media use is only one aspect of several factors that simultaneously affect well-being.
Is it really realistic to expect that extremely changing only _one_ of these aspects should manifest in a detectable change in well-being?
Or would it make more sense to expect that thoroughly committing to say _two_ activities (e.g. regularly exercising _and_ establishing a reading habit) should then cause a detectable improvement in well-being?
Practically, this would imply a SESOI half as large as I have defined here, namely _b_ = |.15| for well-being and _b_ = |.075| for affect.
In the case of this study, however, reducing the SESOI would not even make a big difference, as also with these more liberal thresholds all but three effect would still be completely in the null region, and no effect would be outside of the null region.
However, at all events I encourage future research to start a thorough conversation on what effect sizes are considered meaningful and what not.
Again, with this study I hope to provide some first input and guidelines.

Both media use and well-being were measured using self-reports.
Measuring well-being with self-reports is adequate, because it by definition requires introspection.
However, it would be preferable to measure social media use objectively, as people cannot reliably estimate their use [@scharkowAccuracySelfreportedInternet2016].
That said, objective measures often cannot capture the content or the motivation of the use, and only very complicated tools recording the actual content (such as the Screenome project) might produce such data.
Unfortunately, such procedures introduce other problems, especially related to privacy.
Hence, for this type of research question it still seems necessary to use self-reported measures, and in many cases they can still be very informative [@verbeijSelfreportedMeasuresSocial2021].

Because the data were collected in a single country, the generalizability of the results is limited.
The results apply primarily to the more Western sphere, and might not hold true in other cultures, especially cultures with a different media landscape or alternative social media channels.
That said, because this is a comparatively large study largely representative of an entire country, and because several waves were collected across a large time span, the results should be at least as generalizable as other typical empirical studies collected in the social sciences.

<!-- Social media use was measured with an ordinal variable, however in the analyses it was treated as a numerical one. -->
<!-- If treated as an ordinal one, it would have been necessary to analyze four different contrasts for each media measure, which plus the differentiation between between and within factor would have produced eight different measures, we would have made the model exceedingly complex. -->

## Conclusion

In this study, COVID-19 related social media use didn't meaningfully affect several indicators of well-being, including life satisfaction, positive affect, and negative affect.
However, factors other than social media use were meaningfully related to well-being, such as physical health, exercise, satisfaction with democracy, or believing that one is in control of one's life.
If it's our aim to improve well-being, it might hence be more fruitful not to focus so much on social media but to address other, more pertinent societal problems related to health care, regular exercise, or a functioning democratic system.

\newpage

# References

<!-- \begingroup -->
<!-- \setlength{\parindent}{-0.5in} -->
<!-- \setlength{\leftskip}{0.5in} -->
<div id = "refs"></div>
<!-- \endgroup -->

\newpage

```{r tab-descriptives, cache=F}
apa_table(tab_desc_dat,
          stub_indents = list(
            "Well-being" = c(1:3),
            "Social media use" = c(4:6),
            "Social media channel" = c(7:11)),
          caption = "Descriptives of the main variables."
          )
```

\newpage

```{r sesoi, warning=F, message=F, fig.cap="Illustration of how confidence intervals are used to test a null region. Here, a trivial effect of social media use on life satisfaction is defined as ranging from b = -.25 to b = .25", fig.width=6, fig.height=2}
# make table with data
d_plot <- tribble(
  ~name, ~type, ~Effect, ~ll, ~ul,
  "1. Accept trivial effect", "Decision Rule", -.02, -.12, .08, 
  "2. Reject trivial effect", "Decision Rule", -.37, -.47, -.27,
  "3. Reject positive effect", "Decision Rule", -.22, -.27, -.17,
  "4. Suspend judgement", "Decision Rule", -.1, -.30, .10,
) %>% 
  mutate(
    name = factor(name, levels = name),
    name = fct_rev(name)
         )

# design plot
plot <- ggplot(d_plot, aes(y = name, x = Effect)) +
  geom_vline(xintercept = 0, color = "darkgrey") + 
  geom_vline(xintercept = -.25, color = "darkgrey", linetype = "dashed") +
  geom_vline(xintercept = .25, color = "darkgrey", linetype = "dashed") +
  geom_point(aes(Effect)) +
  geom_errorbarh(aes(xmin = ll, xmax = ul), height = .5) +
  theme(axis.title.y = element_blank()) +
  labs(x = "Effect Size (b)",
       caption = "Smallest effect size of interest: b = |.25|
                  Null region: b = -.25, .25")

# ggsave("figures/figure_intervals.png", height = 3.5)
plot
```

\newpage

```{r descriptives, fig.cap="Development of well-being and media use measures across the pandemic. Values obtained from mixed effect models, with participants and waves as grouping factors and without additional predictors.", out.width = "\\textwidth", cache=F, warning=F, message=F, prompt=FALSE}
# print(fig_desc)
knitr::include_graphics("figures/fig_descriptives.png")
```

\newpage

```{r res-activity, fig.cap="The effects of various types of social media use on three indicators of well-being. The black estimates show the effects controlled for a large number of covariates (see text; preregistered); the grey estimates are without control variables (exploratory). The SESOI was b = |0.30| for life satisfaction and b = |0.15| for affect. Hence, all of the reported effects are not considered meaningful.", out.width = "\\textwidth", cache=F, warning=F, message=F, fig.width=6, fig.height=3}
fig_results_activity
# knitr::include_graphics("figures/fig_results_activity.png")
```

\newpage

```{r res-channels, fig.cap="The effects of using various social media applications on three indicators of well-being. The black estimates show the effects controlled for a large number of covariates (see text; preregistered); the grey estimates are without control variables (exploratory). The SESOI was b = |0.30| for life satisfaction and b = |0.15| for affect. Hence, all of the reported effects are not considered meaningful.", out.width = "\\textwidth", cache=F, warning=F, message=F, fig.width=6, fig.height=4}
# knitr::include_graphics("figures/fig_results_channels.png")
fig_results_channels
```

\newpage

```{r res-control, fig.cap="Results of selected covariates. All variables were standardize except 'Male'  and ‘Employed in public service', because there were measured on a binary scale.", out.width = "\\textwidth", cache=F, warning=F, message=F, fig.width=6, fig.height=3}
fig_results_control_std
# knitr::include_graphics("figures/fig_results_control_std.png")
```

\newpage

# Competing Interests

I declare no competing interests.
  
# Supplementary Material

All the stimuli, presentation materials, analysis scripts, and a reproducible version of the manuscript can be found on the companion website (https://XMtRA.github.io/Austrian_Corona_Panel_Project).

# Data Accessibility Statement

The data are shared on AUSSDA, see https://doi.org/10.11587/28KQNS.
The data can only be used for scientific purposes.

# Acknowledgements

I would like to thank BLINDED for providing valuable feedback on this manuscript.
